{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Наивный Байесовский классификатор"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разберём один из самых простых методов классификации &mdash; наивный байесовский классификатор. Несмотря на его простоту в некоторых задачах он работает даже лучше других, более сложных моделей. В любом случае, наивный байесовский классификатор содержит в себе важные теоретические идеи, поэтому с ним в любом случае полезно ознакомиться. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Применение при детекции спама.\n",
    "\n",
    "Данные для решения задачи детекции спама можно сделать следующим образом:\n",
    "1. Взять набор размеченных текстовых сообщений, часть которых размечена как спам, а остальные &mdash; как не спам;\n",
    "2. Зафиксировать словарь, например, взяв все слова, встречающиеся в наборе текстовых сообщений;\n",
    "3. Преобразовать текстовые данные в целочисленные, посчитав для каждого слова из словаря, встречается ли оно в данном сообщении.\n",
    "\n",
    "Таким образом, каждому предложению соответствует вектор из нулей и единиц длины, равной мощности словаря. На полученных данных уже стандартным образом можно обучить наивный байесовский классификатор.\n",
    "\n",
    "При реализации класса для наивного байесовского классификатора надо помнить один очень важный на практике момент: произведение вероятностей большого количества чисел может очень быстро сравняться с нулем при вычислении на компьютере, так как компьютеру может не хватить вычислительной точности. Поэтому при реализации стоит использовать **логарифмы вероятностей**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Применим наивный байесовский классификатор к конкретному датасету https://archive.ics.uci.edu/ml/datasets/SMS+Spam+Collection.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-16T04:16:51.087100Z",
     "start_time": "2021-02-16T04:16:50.443634Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Чтение данных.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-16T04:16:51.104463Z",
     "start_time": "2021-02-16T04:16:51.089002Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "labels = []\n",
    "messages = []\n",
    "\n",
    "with open('SMSSpamCollection.txt', 'r') as fin:\n",
    "    for line in fin:\n",
    "        cur_label, cur_message = line.split('\\t')\n",
    "        labels.append(cur_label)\n",
    "        messages.append(cur_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-16T04:16:51.120083Z",
     "start_time": "2021-02-16T04:16:51.107101Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ok lar... Joking wif u oni...\\n</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                data label\n",
       "0  Go until jurong point, crazy.. Available only ...   ham\n",
       "1                    Ok lar... Joking wif u oni...\\n   ham\n",
       "2  Free entry in 2 a wkly comp to win FA Cup fina...  spam\n",
       "3  U dun say so early hor... U c already then say...   ham\n",
       "4  Nah I don't think he goes to usf, he lives aro...   ham"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_df = pd.DataFrame()\n",
    "raw_df['data'] = messages\n",
    "raw_df['label'] = labels\n",
    "raw_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В датасете метки бывают 2 видов: \n",
    "* `ham` &mdash; означает, что сообщение **не является спамом**,\n",
    "* `spam` &mdash; означает, что сообщение **является спамом**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Предобработка данных.**\n",
    "\n",
    "Очевидно, что сразу в таком виде нельзя передавать данные наивному байесовскому классификатору. Их надо привести к численному виду. \n",
    "\n",
    "Столбец `label` привести к численному виду можно очень просто."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-16T04:16:51.136846Z",
     "start_time": "2021-02-16T04:16:51.121608Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ok lar... Joking wif u oni...\\n</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                data  label\n",
       "0  Go until jurong point, crazy.. Available only ...      0\n",
       "1                    Ok lar... Joking wif u oni...\\n      0\n",
       "2  Free entry in 2 a wkly comp to win FA Cup fina...      1\n",
       "3  U dun say so early hor... U c already then say...      0\n",
       "4  Nah I don't think he goes to usf, he lives aro...      0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_df['label'] = (raw_df['label'] == 'spam') * 1\n",
    "raw_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для преобразования текстовых сообщений воспользуемся `CountVectorizer`, работающему по принципу мешка слов (*bag of words*). Он имеет следующие гиперпараметры:\n",
    "\n",
    "* `max_df` &mdash; максимальная доля сообщений, в которых может встречатся слово из словаря, то есть в словарь не включаются слишком **частые** слова, что помогает бороться со стоп-словами;\n",
    "* `min_df` &mdash; минимальная доля сообщений, в которых может встречатся слово из словаря, то есть в словарь не включаются слишком **редкие** слова;\n",
    "* `max_features` &mdash; максимальное возможное количество выбранных слов, они выбираются среди наиболее частых;\n",
    "* `stop_words` &mdash; можно просто взять и задать стоп-слова, которые не будут добавлены в словарь ни при каких обстоятельствах."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-16T04:16:51.145736Z",
     "start_time": "2021-02-16T04:16:51.138592Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-16T04:16:51.235465Z",
     "start_time": "2021-02-16T04:16:51.147791Z"
    }
   },
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(min_df=0.03)\n",
    "transformed_data = vectorizer.fit_transform(messages).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Напечатаем весь мешок слов и их количество."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-16T04:16:51.240925Z",
     "start_time": "2021-02-16T04:16:51.237052Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66\n",
      "['all', 'am', 'and', 'are', 'at', 'be', 'but', 'call', 'can', 'come', 'day', 'do', 'for', 'free', 'from', 'get', 'go', 'good', 'got', 'gt', 'have', 'he', 'how', 'if', 'in', 'is', 'it', 'its', 'just', 'know', 'like', 'll', 'love', 'lt', 'me', 'my', 'no', 'not', 'now', 'of', 'ok', 'on', 'only', 'or', 'out', 'send', 'so', 'text', 'that', 'the', 'then', 'there', 'this', 'time', 'to', 'up', 'ur', 'want', 'was', 'we', 'what', 'when', 'will', 'with', 'you', 'your']\n"
     ]
    }
   ],
   "source": [
    "print(len(vectorizer.get_feature_names()))\n",
    "print(vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как видим, сообщения автоматически были порезаны на слова, а слова переведены в нижний регистр."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на преобразованные данные."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-16T04:16:51.252787Z",
     "start_time": "2021-02-16T04:16:51.243257Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 3 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 1 0 0 0 0 0\n",
      "  1 0 1 0 1 0 0 0 0 1 0 0 0 0 0 1 0 0 2 1 0 0 0 0 0 0 0 0 1 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 2 0 0 0 2 1\n",
      "  0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0]\n",
      " [1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 3]\n",
      " [0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 1 0]\n",
      " [0 0 0 0 0 0 0 1 0 0 0 0 1 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 1 0 1 0 0 0 0 0 2 0 0 0 0 2 0 0 0 0 0 0 0 0 1 0 1]]\n"
     ]
    }
   ],
   "source": [
    "print(transformed_data[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Классификатор**\n",
    "\n",
    "В библиотеке `sklearn` имеются следующие реализации наивного байесовского классификатора:\n",
    "\n",
    "1. `BernoulliNB` &mdash; байесовский классификатор для данных, в которых все признаки являются бинарными;\n",
    "2. `MultinomialNB` &mdash; байесовский классификатор для данных, в которых все признаки являются дискретными;\n",
    "3. `GaussianNB` &mdash; байесовский классификатор для вещественных данных, каждый из признаков которых имеет нормальное распределение.\n",
    "\n",
    "Первые два метода имеют следующие параметры:\n",
    "* `alpha` &mdash; коэффициент сглаживания Лапласа или Линдсона, при фиксированном значении `alpha` условные плотности будут записаны следующим образом:\n",
    "$$P(X_j=x_j|Y=y) = \\frac{\\#\\{ i : Y_i = y \\text{ & } X_{ij} = x_j\\} + \\alpha}{\\#\\{i: Y_i = y\\} + \\alpha k_j},$$\n",
    "    где $k_j$ &mdash; количество различных значений признака $x_j$; при `alpha=0` сглаживания не происходит и получаются стандартные формулы для условных вероятностей; \n",
    "* `class_prior` &mdash; арпиорные вероятности принадлежности каждому из классов;\n",
    "* `fit_prior` &mdash; булевский параметр автоматического подбора априорных вероятностей принадлежности классам на основании данных.\n",
    "\n",
    "Если ни `class_prior`, ни `fit_prior` не указаны, то априорное распределение принимается равномерным."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Гауссовский наивный байесовский классификатор предполагает распределение при фиксированном классе гауссовским:\n",
    "$$P(X_i = x_i | Y = y) = \\frac{1}{\\sqrt{2\\pi \\sigma_y^2}} \\cdot \\exp \\left( -\\frac{(x_i - \\mu_y)^2}{2\\sigma_y^2} \\right),$$\n",
    "где $\\mu_y$ и $\\sigma_y$ оцениваются методом максимального правдоподобия."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В нашей текущей задаче для признаков, описывающих количество вхождений каждого слова из словаря в сообщение, логично использовать `MultinomialNB`. Однако после мы сравним точность предсказаний `MultinomialNB` с точностью предсказаний `BernoulliNB` для бинарных признаков: каждый признак является индикатором того, присутствует ли данное слово из словаря в сообщении."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-16T04:16:51.262968Z",
     "start_time": "2021-02-16T04:16:51.254313Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "multinomial_nb = MultinomialNB()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Еще раз посмотрим на данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-16T04:16:51.270674Z",
     "start_time": "2021-02-16T04:16:51.264945Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 1, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformed_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как обычно, разделим данные на обучающую выборку и на тестовую."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-16T04:16:51.281362Z",
     "start_time": "2021-02-16T04:16:51.272307Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    transformed_data, raw_df['label'], random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучаем модель и смотрим качество на тестовой выборке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-16T04:16:51.297552Z",
     "start_time": "2021-02-16T04:16:51.282756Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.944\n",
      "f1 score: 0.785\n"
     ]
    }
   ],
   "source": [
    "multinomial_nb.fit(X_train, y_train)\n",
    "predictions = multinomial_nb.predict(X_test)\n",
    "\n",
    "print(f'accuracy: {accuracy_score(y_test, predictions) :.3}')\n",
    "print(f'f1 score: {f1_score(y_test, predictions) :.3}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Результат получился весьма неплохой.\n",
    "\n",
    "А теперь посмотрим, как с этой же задачей справится наивный байесовский классификатор на бинарных данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-16T04:16:51.304381Z",
     "start_time": "2021-02-16T04:16:51.299340Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train = (X_train > 0) * 1\n",
    "X_test = (X_test > 0) * 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-16T04:16:51.311037Z",
     "start_time": "2021-02-16T04:16:51.305809Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "bernoulli_nb = BernoulliNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-16T04:16:51.330754Z",
     "start_time": "2021-02-16T04:16:51.312311Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.95\n",
      "f1 score: 0.806\n"
     ]
    }
   ],
   "source": [
    "bernoulli_nb.fit(X_train, y_train)\n",
    "predictions = bernoulli_nb.predict(X_test)\n",
    "\n",
    "print(f'accuracy: {accuracy_score(y_test, predictions) :.3}')\n",
    "print(f'f1 score: {f1_score(y_test, predictions) :.3}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Вывод.**\n",
    "\n",
    "Результат получился достаточно неожиданный. Наивный байесовский классификатор, обученный на бинаризованных данных показал более высокую точность классификации."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. Больший размер словаря**\n",
    "\n",
    "А теперь посмотрим, что будет, если мы возьмём другое количество слов для словаря.\n",
    "\n",
    "It's gonna be huge!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-16T04:16:51.509419Z",
     "start_time": "2021-02-16T04:16:51.332102Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5574, 8713)\n"
     ]
    }
   ],
   "source": [
    "huge_vectorizer = CountVectorizer()\n",
    "huge_data = huge_vectorizer.fit_transform(messages).toarray()\n",
    "print(huge_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-16T04:16:51.662816Z",
     "start_time": "2021-02-16T04:16:51.512576Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    huge_data, raw_df['label'], random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-16T04:16:52.022065Z",
     "start_time": "2021-02-16T04:16:51.664739Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.985\n",
      "f1 score: 0.945\n"
     ]
    }
   ],
   "source": [
    "multinomial_nb.fit(X_train, y_train)\n",
    "predictions = multinomial_nb.predict(X_test)\n",
    "\n",
    "print(f'accuracy: {accuracy_score(y_test, predictions) :.3}')\n",
    "print(f'f1 score: {f1_score(y_test, predictions) :.3}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-16T04:16:52.592264Z",
     "start_time": "2021-02-16T04:16:52.028344Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.981\n",
      "f1 score: 0.925\n"
     ]
    }
   ],
   "source": [
    "bernoulli_nb.fit(X_train, y_train)\n",
    "predictions = bernoulli_nb.predict(X_test)\n",
    "\n",
    "print(f'accuracy: {accuracy_score(y_test, predictions) :.3}')\n",
    "print(f'f1 score: {f1_score(y_test, predictions) :.3}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Вывод.**\n",
    "\n",
    "От увеличения количества рассматриваемых слов в данном случае точность предсказаний возрасла как для наивного байесовского классификатора над категориальными признаками, так и для классификатора над бинарными признаками."
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
